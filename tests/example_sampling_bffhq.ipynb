{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca70df83",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
                "\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "import himyb.models.ddpmpp as ddpmpp\n",
                "import himyb.training.save_load as save_load\n",
                "import himyb.models.preconditioning as preconditioning\n",
                "import himyb.sampler.sampler as sampler\n",
                "import himyb.sampler.generate as generate\n",
                "import himyb.misc_utils as misc_utils\n",
                "\n",
                "%matplotlib inline\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "418d0db0",
            "metadata": {},
            "outputs": [],
            "source": [
                "root_dir = ... # set this to the root directory of the model save\n",
                "device = torch.device(\"cuda\")\n",
                "\n",
                "#load the configurations\n",
                "config_filename = ... #Â set this to the config filename\n",
                "states_filename = ... # set this to the config filename\n",
                "dataset_conf, model_conf, optim_config, cur_img = save_load.load_training_configs(os.path.join(root_dir, \"checkpoints\", config_filename))\n",
                "\n",
                "# create the model\n",
                "internal_model = ddpmpp.DDPMPP(**model_conf)\n",
                "model = preconditioning.EDMPrecond(\n",
                "        model=internal_model,\n",
                ").eval().to(device)\n",
                "\n",
                "#load the weights of the model\n",
                "save_load.load_training_state(file_name=os.path.join(root_dir, \"checkpoints\", states_filename), model=model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "77a2d0e7",
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_n_imgs(\n",
                "    n_imgs_per_class, \n",
                "    num_steps, \n",
                "    model, \n",
                "    device, \n",
                "    guidance_scale=0.0, \n",
                "    use_unconditional_model=True, \n",
                "    s_churn=0, \n",
                "    sample_uncond=False,\n",
                "    return_class_labels=False\n",
                "):\n",
                "    \"\"\"\n",
                "    Sample a specified number of images per class from the model.\n",
                "    Args:\n",
                "        n_imgs_per_class (int): Number of images to sample per class.\n",
                "        num_steps (int): Number of sampling steps.\n",
                "        model (torch.nn.Module): The model to sample from.\n",
                "        device (torch.device): The device to run the sampling on.\n",
                "        guidance_scale (float): Guidance scale of CFG\n",
                "        use_unconditional_model (bool): Whether to use the unconditional model to obtain the unconditional score in CFG\n",
                "        s_churn (float): S_churn parameter for the stochastic sampler (controls the variance of the fresh noise added during sampling,\\\n",
                "            S_churn=0 means deterministic sampling, S_churn>0 means stochastic sampling)\n",
                "        sample_uncond (bool): Whether to sample from the unconditional class (class 0).\n",
                "        return_class_labels (bool): Whether to return the class labels along with the generated images.\n",
                "    \"\"\"\n",
                "    if sample_uncond:\n",
                "        batch_size = n_imgs_per_class * model.label_dim\n",
                "        class_labels = torch.arange(batch_size, device=device, dtype=torch.long) // n_imgs_per_class\n",
                "    else:\n",
                "        batch_size = n_imgs_per_class * (model.label_dim-1)\n",
                "        class_labels = (torch.arange(batch_size, device=device, dtype=torch.long) // n_imgs_per_class)+1\n",
                "    shape = (batch_size, model.in_channels, model.img_resolution, model.img_resolution)\n",
                "    result = sampler.stoch_edm_sampler(\n",
                "        model=model,\n",
                "        class_labels=class_labels, \n",
                "        shape=shape, \n",
                "        s_churn=s_churn, \n",
                "        s_min = 0.01,\n",
                "        s_max = 80,\n",
                "        s_noise = 1.003,\n",
                "        num_steps=num_steps, \n",
                "        return_history=False, \n",
                "        device=device, \n",
                "        guidance_scale=guidance_scale, \n",
                "        use_unconditional_model=use_unconditional_model)\n",
                "    if return_class_labels:\n",
                "        return result[\"generated_imgs\"], class_labels\n",
                "    return result[\"generated_imgs\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72054a22",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_imgs(imgs, n_rows, n_cols, scale_f = 1.) :\n",
                "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*scale_f, n_rows*scale_f))\n",
                "    for i, ax in enumerate(axes.flatten()):\n",
                "        if i >= len(imgs):\n",
                "            break\n",
                "        with misc_utils.DisableImshowWarning():\n",
                "            ax.imshow((imgs[i].permute(1, 2, 0).cpu().numpy()+1)/2)\n",
                "        ax.axis('off')\n",
                "    plt.tight_layout()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5135096e",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_imgs = 80\n",
                "n_steps = 10\n",
                "imgs, cl_labels = sample_n_imgs(\n",
                "    n_imgs_per_class=n_imgs, \n",
                "    num_steps=n_steps, \n",
                "    model=model, \n",
                "    device=device, \n",
                "    guidance_scale=0., \n",
                "    use_unconditional_model=False, \n",
                "    s_churn=0,\n",
                "    sample_uncond=False,\n",
                "    return_class_labels=True\n",
                ")\n",
                "\n",
                "# 0 is the unconditional class when we give the tokens to the model \n",
                "# so to obtain the class labels as they are in the dataset we need to subtract 1\n",
                "cl_labels -= 1 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "351e14df",
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_imgs(imgs, 8,int(n_imgs/4), 2)\n",
                "plt.show();"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d27425c6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_imgs(imgs, class_labels, folder) :\n",
                "    os.makedirs(folder, exist_ok=True)\n",
                "    cur_idx = len(os.listdir(folder))\n",
                "    for i, img in enumerate(imgs):\n",
                "        img = ((img.permute(1, 2, 0).cpu().numpy()+1)/2).clip(0, 1)\n",
                "        plt.imsave(os.path.join(folder, f\"img_{i+cur_idx:05d}_{int(class_labels[i].item())}.png\"), img)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c635aa8",
            "metadata": {},
            "outputs": [],
            "source": [
                "SAVE_FOLDER = os.path.join(root_dir, \"generated_imgs\")\n",
                "save_imgs(imgs, cl_labels, SAVE_FOLDER)\n",
                "print(f\"Saved generated images to {SAVE_FOLDER}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cond_llh",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
